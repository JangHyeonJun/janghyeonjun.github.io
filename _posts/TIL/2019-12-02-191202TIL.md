---
layout: single

title: "2019-12-02 TIL"
categories:
  - TIL
tags:
  - [TIL, ML, RL]
use_math: true
 
---



- ## [복습] 개념 정리

  - 강화학습 용어 정리
    - Policy, Value based
    - Gradient (Optimizer)(SGD, Momentum, Adam)
    - Costfunction(MSE, Crossentropy), Activationfunction(Perceptron:Step / MP:Sigmoid / DNN: ReLU, tanh / Multi-Class : Softmax)
    - Batch(Matrix 사용 연산 감소)
    - Overfitting 방지
      - L1, L2 Regurarization : 가중치가 클수록 패널티 부여, ($1/2W^2$) 은 $L2$, ($W$)는$L1$
      - Dropout
      - 학습 조기 중단, 데이터셋 추가, 층을 얕게
  - 전산학 개념 정리
  
  
  
- ## ToDo

  - 파트 2 - 9-1 부터 수강하기
  - [CS231N 강좌 공부](http://cs231n.stanford.edu/syllabus.html)
  - 강화학습 알고리즘 공부하기

------

